# AWS Amplify Gen2 + Amazon Transcribe ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒª

## æ¦‚è¦

Amazon Transcribe Streaming APIã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—æ©Ÿèƒ½ã®å®Ÿè£…æ‰‹é †ã¨ã‚³ãƒ¼ãƒ‰é›†ã§ã™ã€‚

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**: React + TypeScript + Vite
- **UI**: Material-UI (MUI)
- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰**: AWS Amplify Gen2
- **éŸ³å£°èªè­˜**: Amazon Transcribe Streaming
- **éŸ³å£°å‡¦ç†**: AudioWorklet API

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

```
transcribe-app/
â”œâ”€â”€ amplify/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ resource.ts
â”‚   â”œâ”€â”€ backend.ts
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ public/
â”‚   â””â”€â”€ audio-processor.js          # AudioWorkletéŸ³å£°å‡¦ç†
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ transcribe/
â”‚   â”‚       â”œâ”€â”€ components/
â”‚   â”‚       â”‚   â””â”€â”€ TranscribeRecorder.tsx
â”‚   â”‚       â”œâ”€â”€ hooks/
â”‚   â”‚       â”‚   â””â”€â”€ useAudioRecorder.ts
â”‚   â”‚       â”œâ”€â”€ services/
â”‚   â”‚       â”‚   â””â”€â”€ transcribeService.ts
â”‚   â”‚       â”œâ”€â”€ types/
â”‚   â”‚       â”‚   â””â”€â”€ index.ts
â”‚   â”‚       â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx
â”œâ”€â”€ package.json
â””â”€â”€ vite.config.ts
```

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. Amplify ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ

```bash
npm create amplify@latest transcribe-app
cd transcribe-app
```

### 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
npm install @mui/material @emotion/react @emotion/styled @mui/icons-material
npm install @aws-sdk/client-transcribe-streaming
```

### 3. Amplify ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®š

#### `amplify/backend.ts`

```typescript
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import {
  Policy,
  PolicyDocument,
  PolicyStatement,
  Effect,
} from "aws-cdk-lib/aws-iam";

const backend = defineBackend({
  auth,
});

// ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ¼ãƒ«ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼ã‚’è¨­å®š
const { cfnUserPool } = backend.auth.resources.cfnResources;
if (cfnUserPool) {
  cfnUserPool.usernameAttributes = [];
  cfnUserPool.policies = {
    passwordPolicy: {
      minimumLength: 6,
      requireLowercase: false,
      requireNumbers: false,
      requireSymbols: false,
      requireUppercase: false,
      temporaryPasswordValidityDays: 30,
    },
  };
}

// AWS Transcribe Streamingã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’è¿½åŠ 
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(
  new Policy(
    backend.auth.resources.authenticatedUserIamRole.stack,
    "TranscribeStreamingPolicy",
    {
      document: new PolicyDocument({
        statements: [
          new PolicyStatement({
            effect: Effect.ALLOW,
            actions: [
              "transcribe:StartStreamTranscription",
              "transcribe:StartStreamTranscriptionWebSocket",
            ],
            resources: ["*"],
          }),
        ],
      }),
    }
  )
);
```

### 4. éŸ³å£°å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼

#### `public/audio-processor.js`

```javascript
class AudioProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.bufferSize = 512;
    this.buffer = new Float32Array(this.bufferSize);
    this.bufferIndex = 0;
  }

  process(inputs, outputs) {
    const input = inputs[0];
    if (input.length > 0) {
      const inputChannel = input[0];

      for (let i = 0; i < inputChannel.length; i++) {
        this.buffer[this.bufferIndex] = inputChannel[i];
        this.bufferIndex++;

        if (this.bufferIndex >= this.bufferSize) {
          this.port.postMessage({
            type: "audiodata",
            buffer: Array.from(this.buffer),
          });
          this.bufferIndex = 0;
        }
      }
    }

    return true;
  }
}

registerProcessor("audio-processor", AudioProcessor);
```

### 5. å‹å®šç¾©

#### `src/features/transcribe/types/index.ts`

```typescript
export interface TranscriptionResult {
  transcript: string;
  timestamp: number;
}

export interface RecordingState {
  isRecording: boolean;
  isProcessing: boolean;
  error: string | null;
}

export interface AudioChunk {
  data: Blob;
  timestamp: number;
}
```

### 6. Transcribe ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹

#### `src/features/transcribe/services/transcribeService.ts`

```typescript
import { fetchAuthSession } from "aws-amplify/auth";
import {
  TranscribeStreamingClient,
  StartStreamTranscriptionCommand,
} from "@aws-sdk/client-transcribe-streaming";

export const createTranscribeStreamingClient = async () => {
  try {
    const session = await fetchAuthSession();
    const credentials = session.credentials;

    if (!credentials) {
      throw new Error("èªè¨¼æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ");
    }

    const transcribeClient = new TranscribeStreamingClient({
      region: "ap-northeast-1",
      credentials: {
        accessKeyId: credentials.accessKeyId,
        secretAccessKey: credentials.secretAccessKey,
        sessionToken: credentials.sessionToken,
      },
    });

    return transcribeClient;
  } catch (error) {
    console.error("âŒ TranscribeStreamingClientä½œæˆã‚¨ãƒ©ãƒ¼:", error);
    throw error;
  }
};

export const encodePCMChunk = (chunk: Float32Array): Uint8Array => {
  const buffer = new ArrayBuffer(chunk.length * 2);
  const view = new DataView(buffer);
  let offset = 0;

  for (let i = 0; i < chunk.length; i++, offset += 2) {
    const s = Math.max(-1, Math.min(1, chunk[i]));
    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
  }

  return new Uint8Array(buffer);
};

export const createAudioStream = async function* (
  mediaStream: MediaStream,
  onStop: () => boolean,
  sampleRate: number = 16000
): AsyncGenerator<{ AudioEvent: { AudioChunk: Uint8Array } }> {
  const audioContext = new AudioContext({ sampleRate });
  const source = audioContext.createMediaStreamSource(mediaStream);

  await audioContext.audioWorklet.addModule("/audio-processor.js");
  const processor = new AudioWorkletNode(audioContext, "audio-processor");

  const audioQueue: Uint8Array[] = [];
  let isProcessing = true;
  let chunkCount = 0;

  processor.port.onmessage = (event) => {
    if (!isProcessing) return;

    if (event.data.type === "audiodata") {
      const inputData = new Float32Array(event.data.buffer);
      const encodedChunk = encodePCMChunk(inputData);

      if (encodedChunk.length > 0) {
        audioQueue.push(encodedChunk);
        chunkCount++;
      }
    }
  };

  source.connect(processor);
  processor.connect(audioContext.destination);

  try {
    while (!onStop() && isProcessing) {
      if (audioQueue.length > 0) {
        const chunk = audioQueue.shift()!;
        yield { AudioEvent: { AudioChunk: chunk } };
      }
      await new Promise((resolve) => setTimeout(resolve, 10));
    }
  } finally {
    isProcessing = false;
    processor.disconnect();
    source.disconnect();
    await audioContext.close();
  }
};

export const startTranscribeStreaming = async (
  mediaStream: MediaStream,
  onTranscriptionResult: (text: string, isFinal: boolean) => void,
  onStop: () => boolean,
  sampleRate: number = 16000
) => {
  try {
    const client = await createTranscribeStreamingClient();
    const audioStream = createAudioStream(mediaStream, onStop, sampleRate);

    const command = new StartStreamTranscriptionCommand({
      LanguageCode: "ja-JP",
      MediaEncoding: "pcm",
      MediaSampleRateHertz: sampleRate,
      AudioStream: audioStream,
    });

    const response = await client.send(command);

    if (response.TranscriptResultStream) {
      let eventCount = 0;

      for await (const event of response.TranscriptResultStream) {
        eventCount++;

        if (event.TranscriptEvent && event.TranscriptEvent.Transcript) {
          const results = event.TranscriptEvent.Transcript.Results;
          if (results && results.length > 0) {
            const result = results[0];
            const transcript = result.Alternatives?.[0]?.Transcript || "";
            const isFinal = !result.IsPartial;

            if (transcript) {
              onTranscriptionResult(transcript, isFinal);
            }
          }
        }
      }
    }
  } catch (error) {
    console.error("âŒ Transcribe Streamingã‚¨ãƒ©ãƒ¼:", error);
    throw error;
  }
};
```

### 7. éŸ³å£°éŒ²éŸ³ãƒ•ãƒƒã‚¯

#### `src/features/transcribe/hooks/useAudioRecorder.ts`

```typescript
import { useState, useRef, useCallback, useEffect } from "react";
import type { RecordingState, TranscriptionResult } from "../types";
import { startTranscribeStreaming } from "../services/transcribeService";

export const useAudioRecorder = () => {
  const [state, setState] = useState<RecordingState>({
    isRecording: false,
    isProcessing: false,
    error: null,
  });

  const [transcriptions, setTranscriptions] = useState<TranscriptionResult[]>(
    []
  );
  const [currentTranscript, setCurrentTranscript] = useState<string>("");

  const streamRef = useRef<MediaStream | null>(null);
  const isStoppedRef = useRef<boolean>(false);
  const streamingPromiseRef = useRef<Promise<void> | null>(null);

  const onTranscriptionResult = useCallback(
    (text: string, isFinal: boolean) => {
      if (isFinal) {
        // ç¢ºå®šçµæœã‚’å±¥æ­´ã«è¿½åŠ 
        if (text.trim()) {
          setTranscriptions((prev) => [
            ...prev,
            {
              transcript: text,
              timestamp: Date.now(),
            },
          ]);
        }
        setCurrentTranscript(""); // æš«å®šçµæœã‚’ã‚¯ãƒªã‚¢
      } else {
        // æš«å®šçµæœã‚’è¡¨ç¤º
        setCurrentTranscript(text);
      }
    },
    []
  );

  const startRecording = useCallback(async () => {
    try {
      setState((prev) => ({ ...prev, error: null, isProcessing: true }));

      // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆ16kHzã«è¨­å®šï¼‰
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      streamRef.current = stream;
      isStoppedRef.current = false;

      // Transcribeã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹
      streamingPromiseRef.current = startTranscribeStreaming(
        stream,
        onTranscriptionResult,
        () => isStoppedRef.current,
        16000
      );

      setState((prev) => ({
        ...prev,
        isRecording: true,
        isProcessing: false,
      }));

      // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†ã‚’å¾…æ©Ÿï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼‰
      streamingPromiseRef.current.catch((error) => {
        console.error("âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼:", error);
        setState((prev) => ({
          ...prev,
          error:
            error instanceof Error ? error.message : "éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ",
        }));
      });
    } catch (error) {
      console.error("âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:", error);
      setState((prev) => ({
        ...prev,
        error:
          error instanceof Error ? error.message : "éŒ²éŸ³é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ",
        isProcessing: false,
      }));
    }
  }, [onTranscriptionResult]);

  const stopRecording = useCallback(async () => {
    try {
      isStoppedRef.current = true;

      // MediaStreamåœæ­¢
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
        streamRef.current = null;
      }

      setState((prev) => ({ ...prev, isRecording: false }));
      setCurrentTranscript("");

      // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®Œäº†ã‚’å¾…æ©Ÿ
      if (streamingPromiseRef.current) {
        try {
          await streamingPromiseRef.current;
        } catch (error) {}
        streamingPromiseRef.current = null;
      }
    } catch (error) {
      console.error("âŒ éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼:", error);
      setState((prev) => ({
        ...prev,
        error:
          error instanceof Error ? error.message : "éŒ²éŸ³åœæ­¢ã«å¤±æ•—ã—ã¾ã—ãŸ",
      }));
    }
  }, []);

  const clearTranscriptions = useCallback(() => {
    setTranscriptions([]);
    setCurrentTranscript("");
  }, []);

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      isStoppedRef.current = true;
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  return {
    state,
    transcriptions,
    currentTranscript,
    startRecording,
    stopRecording,
    clearTranscriptions,
  };
};
```

### 8. UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

#### `src/features/transcribe/components/TranscribeRecorder.tsx`

```typescript
import {
  Box,
  Button,
  Typography,
  IconButton,
  Alert,
  CircularProgress,
  List,
  ListItem,
  ListItemText,
  Divider,
} from "@mui/material";
import { Mic, MicOff, Clear } from "@mui/icons-material";
import { useAudioRecorder } from "../hooks/useAudioRecorder";

export const TranscribeRecorder = () => {
  const {
    state,
    transcriptions,
    currentTranscript,
    startRecording,
    stopRecording,
    clearTranscriptions,
  } = useAudioRecorder();

  const formatTimestamp = (timestamp: number): string => {
    return new Date(timestamp).toLocaleTimeString("ja-JP");
  };

  return (
    <Box sx={{ maxWidth: 800, mx: "auto", p: 2 }}>
      <Box sx={{ display: "flex", justifyContent: "center", mb: 3 }}>
        {!state.isRecording ? (
          <Button
            variant="text"
            color="primary"
            size="large"
            startIcon={<Mic />}
            onClick={startRecording}
            disabled={state.isProcessing}
            sx={{ minWidth: 150 }}
          >
            start recording
          </Button>
        ) : (
          <Button
            variant="text"
            color="error"
            size="large"
            startIcon={<MicOff />}
            onClick={stopRecording}
            sx={{ minWidth: 150 }}
          >
            stop recording
          </Button>
        )}
      </Box>

      {state.isProcessing && (
        <Box sx={{ display: "flex", justifyContent: "center", mb: 2 }}>
          <CircularProgress size={24} />
          <Typography variant="body2" sx={{ ml: 1 }}>
            transcribing...
          </Typography>
        </Box>
      )}

      {state.error && (
        <Alert severity="error" sx={{ mb: 2 }}>
          {state.error}
        </Alert>
      )}

      <Box sx={{ p: 2 }}>
        <Box
          sx={{
            display: "flex",
            justifyContent: "space-between",
            alignItems: "center",
            mb: 2,
          }}
        >
          <Typography variant="h6" component="h3">
            result
          </Typography>
          {transcriptions.length > 0 && (
            <IconButton
              onClick={clearTranscriptions}
              size="small"
              title="clear"
            >
              <Clear />
            </IconButton>
          )}
        </Box>

        {/* ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æš«å®šçµæœ */}
        {currentTranscript && (
          <Box
            sx={{
              mb: 2,
              p: 2,
              backgroundColor: "#f0f8ff",
              borderRadius: 1,
              border: "1px dashed #2196f3",
            }}
          >
            <Typography
              variant="caption"
              color="primary"
              sx={{ fontSize: "0.75rem", fontWeight: "bold" }}
            >
              transcribing...
            </Typography>
            <Typography
              variant="body1"
              sx={{
                wordBreak: "break-word",
                fontStyle: "italic",
                color: "primary.main",
                mt: 0.5,
              }}
            >
              {currentTranscript}
            </Typography>
          </Box>
        )}

        {transcriptions.length === 0 && !currentTranscript ? (
          <Typography
            variant="body2"
            color="text.secondary"
            sx={{ textAlign: "center", py: 4 }}
          >
            start recording to see real-time transcription
          </Typography>
        ) : (
          <List sx={{ maxHeight: 400, overflow: "auto" }}>
            {transcriptions.map((transcription, index) => (
              <Box key={transcription.timestamp}>
                <ListItem alignItems="flex-start" sx={{ px: 0 }}>
                  <ListItemText
                    primary={transcription.transcript}
                    secondary={formatTimestamp(transcription.timestamp)}
                    primaryTypographyProps={{
                      variant: "body1",
                      sx: { wordBreak: "break-word" },
                    }}
                    secondaryTypographyProps={{
                      variant: "caption",
                      color: "text.secondary",
                    }}
                  />
                </ListItem>
                {index < transcriptions.length - 1 && <Divider />}
              </Box>
            ))}
          </List>
        )}
      </Box>
    </Box>
  );
};
```

### 9. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆè¨­å®š

#### `src/features/transcribe/index.ts`

```typescript
export { TranscribeRecorder } from "./components/TranscribeRecorder";
export { useAudioRecorder } from "./hooks/useAudioRecorder";
export { startTranscribeStreaming } from "./services/transcribeService";
export * from "./types";
```

### 10. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

#### `src/App.tsx`

```typescript
import { Authenticator } from "@aws-amplify/ui-react";
import { ThemeProvider, createTheme } from "@mui/material/styles";
import {
  CssBaseline,
  AppBar,
  Toolbar,
  Typography,
  Button,
  Container,
} from "@mui/material";
import { TranscribeRecorder } from "./features/transcribe";

const theme = createTheme({
  palette: {
    mode: "light",
    primary: {
      main: "#1976d2",
    },
  },
});

function App() {
  return (
    <ThemeProvider theme={theme}>
      <CssBaseline />
      <Authenticator>
        {({ signOut }) => (
          <>
            <AppBar position="static" sx={{ backgroundColor: "#ffffff", boxShadow: "none" }}>
              <Toolbar>
                <Typography
                  variant="h6"
                  component="div"
                  sx={{ flexGrow: 1, color: "#000000" }}
                >
                  transcribe app
                </Typography>
                <Button color="inherit" onClick={signOut} sx={{ color: "#000000" }}>
                  sign out
                </Button>
              </Toolbar>
            </AppBar>

            <Container maxWidth="lg" sx={{ mt: 4, mb: 4 }}>
              <TranscribeRecorder />
            </Container>
          </>
        )}
      </Authenticator>
    </ThemeProvider>
  );
}

export default App;
```

#### `src/main.tsx`

```typescript
import { Amplify } from "aws-amplify";
import { StrictMode } from "react";
import { createRoot } from "react-dom/client";
import App from "./App.tsx";
import "@aws-amplify/ui-react/styles.css";
import outputs from "../amplify_outputs.json";

Amplify.configure(outputs);

createRoot(document.getElementById("root")!).render(
  <StrictMode>
    <App />
  </StrictMode>
);
```

### 11. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è¨­å®š

#### `package.json` (ä¾å­˜é–¢ä¿‚éƒ¨åˆ†)

```json
{
  "dependencies": {
    "@aws-amplify/ui-react": "^6.12.0",
    "@aws-sdk/client-transcribe-streaming": "^3.x.x",
    "@emotion/react": "^11.14.0",
    "@emotion/styled": "^11.14.1",
    "@mui/icons-material": "^7.3.1",
    "@mui/material": "^7.3.1",
    "aws-amplify": "^6.15.5",
    "react": "^19.1.1",
    "react-dom": "^19.1.1"
  }
}
```

## å®Ÿè¡Œæ‰‹é †

### 1. é–‹ç™ºç’°å¢ƒã®èµ·å‹•ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®Ÿè¡Œï¼‰

```bash
npx ampx sandbox
```

### 2. ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹

```
http://localhost:5173
```

### 3. èªè¨¼ã¨ãƒ†ã‚¹ãƒˆ

1. ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—/ã‚µã‚¤ãƒ³ã‚¤ãƒ³
2. ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯
3. ã€Œstart recordingã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
4. è©±ã™ â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—è¡¨ç¤º
5. ã€Œstop recordingã€ã§åœæ­¢

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼

- HTTPSã¾ãŸã¯localhostã§ã®ã¿å‹•ä½œ
- ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒã‚¤ã‚¯æ¨©é™ã‚’ç¢ºèª

### Transcribeã‚¨ãƒ©ãƒ¼

- IAMæ¨©é™ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
- èªè¨¼ãŒå®Œäº†ã—ã¦ã„ã‚‹ã‹ç¢ºèª

### AudioWorkletã‚¨ãƒ©ãƒ¼

- `/audio-processor.js`ãƒ•ã‚¡ã‚¤ãƒ«ãŒ`public/`ã«ã‚ã‚‹ã‹ç¢ºèª
- HTTPSæ¥ç¶šãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹

## ä¸»è¦æ©Ÿèƒ½

- âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—
- âœ… æš«å®šçµæœã¨ç¢ºå®šçµæœã®åŒºåˆ¥è¡¨ç¤º
- âœ… æ–‡å­—èµ·ã“ã—å±¥æ­´ã®ä¿å­˜
- âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- âœ… ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–UI
- âœ… AWSèªè¨¼çµ±åˆ

## éŸ³å£°è¨­å®š

- **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ**: 16kHz
- **éŸ³å£°å½¢å¼**: PCM
- **è¨€èª**: æ—¥æœ¬èª (ja-JP)
- **ãƒãƒ£ãƒ³ãƒãƒ«**: ãƒ¢ãƒãƒ©ãƒ«

## ğŸš¨ é‡è¦ï¼šãªãœæœ€åˆã®å®Ÿè£…ã¯å¤±æ•—ã—ãŸã®ã‹

### âŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³1: è¤‡é›‘ãªã‚¯ãƒ©ã‚¹è¨­è¨ˆ

**ã‚„ã£ã¦ã—ã¾ã£ãŸã“ã¨ï¼š**

```typescript
export class RealTimeTranscriber {
  private audioQueue: Uint8Array[] = [];
  private isStreaming = false;
  // è¤‡é›‘ãªã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°å‡¦ç†
  // è¤‡é›‘ãªé€ä¿¡åˆ¶å¾¡
  // è¤‡é›‘ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
}
```

**å•é¡Œç‚¹ï¼š**

- éåº¦ã«è¤‡é›‘ãªè¨­è¨ˆ
- ãƒ‡ãƒãƒƒã‚°ãŒå›°é›£
- ç„¡é™ãƒ«ãƒ¼ãƒ—ãŒç™ºç”Ÿ
- ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§

**æ•™è¨“ï¼š** ã‚·ãƒ³ãƒ—ãƒ«ã‚¤ã‚ºãƒ™ã‚¹ãƒˆã€‚é–¢æ•°ãƒ™ãƒ¼ã‚¹ã§ååˆ†

---

### âŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³2: éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®èª¤è§£

**ã‚„ã£ã¦ã—ã¾ã£ãŸã“ã¨ï¼š**

```typescript
// éŒ²éŸ³
const mediaRecorder = new MediaRecorder(stream, {
  mimeType: "audio/webm;codecs=opus", // WebMå½¢å¼
});

// Transcribeé€ä¿¡
MediaEncoding: "ogg-opus"; // âŒ ä¸æ•´åˆ
```

**å•é¡Œç‚¹ï¼š**

- WebM â‰  OGGå½¢å¼
- Amazon TranscribeãŒèªè­˜ã§ããªã„
- ç©ºã®çµæœã—ã‹è¿”ã‚‰ãªã„

**æ­£è§£ï¼š**

```typescript
// AudioWorkletã§PCMå½¢å¼ã«å¤‰æ›
MediaEncoding: "pcm"; // âœ… ç¢ºå®Ÿã«å‹•ä½œ
```

**æ•™è¨“ï¼š** éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®çµ±ä¸€ãŒé‡è¦

---

### âŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³3: ScriptProcessorNodeä½¿ç”¨

**ã‚„ã£ã¦ã—ã¾ã£ãŸã“ã¨ï¼š**

```typescript
// å»ƒæ­¢äºˆå®šã®APIä½¿ç”¨
const processor = audioContext.createScriptProcessor(4096, 1, 1);
processor.onaudioprocess = (event) => {
  // é »ç¹ã™ãã‚‹å‡¦ç†ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ
  // ç„¡é™ãƒ«ãƒ¼ãƒ—ã«ãªã‚Šã‚„ã™ã„
};
```

**å•é¡Œç‚¹ï¼š**

- ScriptProcessorNodeã¯å»ƒæ­¢äºˆå®š
- ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ãƒ–ãƒ­ãƒƒã‚¯
- å‡¦ç†é »åº¦ãŒé«˜ã™ãã‚‹
- ç„¡é™ãƒ«ãƒ¼ãƒ—ã«ãªã‚Šã‚„ã™ã„

**æ­£è§£ï¼š**

```typescript
// AudioWorkletä½¿ç”¨
await audioContext.audioWorklet.addModule("/audio-processor.js");
const processor = new AudioWorkletNode(audioContext, "audio-processor");
```

**æ•™è¨“ï¼š** æœ€æ–°ã®Web APIã‚’ä½¿ç”¨ã™ã‚‹

---

### âŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³4: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° API ã®èª¤ç”¨

**ã‚„ã£ã¦ã—ã¾ã£ãŸã“ã¨ï¼š**

```typescript
// éŒ²éŸ³å®Œäº†å¾Œã«ä¸€æ‹¬é€ä¿¡
mediaRecorder.onstop = async () => {
  const audioBlob = new Blob(audioChunks);
  // âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIã«å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬é€ä¿¡
  yield { AudioEvent: { AudioChunk: entireAudioFile } };
}
```

**å•é¡Œç‚¹ï¼š**

- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIãªã®ã«ä¸€æ‹¬é€ä¿¡
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒãªã„
- TranscribeãŒæ­£å¸¸ã«å‹•ä½œã—ãªã„

**æ­£è§£ï¼š**

```typescript
// ç¶™ç¶šçš„ãªå°ã•ãªãƒãƒ£ãƒ³ã‚¯é€ä¿¡
while (!onStop()) {
  if (audioQueue.length > 0) {
    const chunk = audioQueue.shift();
    yield { AudioEvent: { AudioChunk: chunk } };
  }
  await new Promise(resolve => setTimeout(resolve, 10));
}
```

**æ•™è¨“ï¼š** ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIã¯ç¶™ç¶šçš„ãªé€ä¿¡ãŒå¿…è¦

---

### âŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³5: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã®ä¸ä¸€è‡´

**ã‚„ã£ã¦ã—ã¾ã£ãŸã“ã¨ï¼š**

```typescript
// éŒ²éŸ³è¨­å®š
sampleRate: 48000; // 48kHz

// Transcribeè¨­å®š
MediaSampleRateHertz: 16000; // âŒ 16kHzï¼ˆä¸ä¸€è‡´ï¼‰
```

**å•é¡Œç‚¹ï¼š**

- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã®ä¸ä¸€è‡´
- éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œãªã„
- èªè­˜ç²¾åº¦ãŒä½ä¸‹

**æ­£è§£ï¼š**

```typescript
// çµ±ä¸€ã™ã‚‹
sampleRate: 16000;
MediaSampleRateHertz: 16000;
```

**æ•™è¨“ï¼š** éŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã§è¨­å®šã‚’çµ±ä¸€

---

## âœ… æˆåŠŸã®ãƒã‚¤ãƒ³ãƒˆ

### 1. ã‚·ãƒ³ãƒ—ãƒ«ãªé–¢æ•°ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

- ã‚¯ãƒ©ã‚¹ã§ã¯ãªãé–¢æ•°ã§å®Ÿè£…
- è²¬ä»»ã‚’æ˜ç¢ºã«åˆ†é›¢
- ãƒ‡ãƒãƒƒã‚°ã—ã‚„ã™ã„æ§‹é€ 

### 2. é©åˆ‡ãªéŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

- AudioWorkletã§PCMå¤‰æ›
- 16kHzã§çµ±ä¸€
- Amazon Transcribeæ¨™æº–ã«æº–æ‹ 

### 3. çœŸã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†

- ç¶™ç¶šçš„ãªå°ã•ãªãƒãƒ£ãƒ³ã‚¯é€ä¿¡
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”
- é©åˆ‡ãªé–“éš”åˆ¶å¾¡

### 4. æœ€æ–°Web APIä½¿ç”¨

- AudioWorkletProcessor
- AsyncGenerator
- éæ¨å¥¨APIã‚’é¿ã‘ã‚‹

## ğŸš« é¿ã‘ã‚‹ã¹ãè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

1. **éåº¦ãªæŠ½è±¡åŒ–**: ã‚·ãƒ³ãƒ—ãƒ«ãŒä¸€ç•ª
2. **è¤‡é›‘ãªã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°**: åŸºæœ¬çš„ãªé€ä¿¡ã§ååˆ†
3. **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›**: æœ€åˆã‹ã‚‰é©åˆ‡ãªå½¢å¼ã‚’é¸æŠ
4. **ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰å‡¦ç†**: WebWorker/AudioWorkletã‚’ä½¿ç”¨
5. **ä¸€æ‹¬å‡¦ç†æ€è€ƒ**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯ç¶™ç¶šçš„å‡¦ç†

## ğŸ“‹ è¨­è¨ˆæ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯çµ±ä¸€ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
- [ ] ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¯ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
- [ ] ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIã‚’æ­£ã—ãä½¿ç”¨ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
- [ ] AudioWorkletã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
- [ ] è¨­è¨ˆã¯ã‚·ãƒ³ãƒ—ãƒ«ã‹ï¼Ÿ

**æœ€é‡è¦ï¼š** è¤‡é›‘ãªå®Ÿè£…ã‚ˆã‚Šã€å‹•ä½œã™ã‚‹ç°¡å˜ãªå®Ÿè£…ã‚’é¸ã¶
